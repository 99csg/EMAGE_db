{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load smplxflame_30 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2004, 165)\n",
      "(2004, 3)\n",
      "(300,)\n",
      "(2004, 100)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "joint_path = \"./dataloaders/utils/data_tools\"\n",
    "data_path = \"./EMAGE/test_sequences/smplxflame_30/2_scott_0_4_4.npz\"\n",
    "m_data = np.load(data_path, allow_pickle=True)\n",
    "print(m_data[\"poses\"].shape)\n",
    "print(m_data[\"trans\"].shape)\n",
    "print(m_data[\"betas\"].shape)\n",
    "print(m_data[\"expressions\"].shape)\n",
    "# 2004 can be different for each data(person) why? time sequence different\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load wave16k data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1477350,) 22050\n",
      "(1072000,)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "audio_data_path=\"./EMAGE/test_sequences/wave16k/2_scott_0_4_4.wav\"\n",
    "audio_each_file, sr = librosa.load(audio_data_path)\n",
    "print(audio_each_file.shape, sr)\n",
    "\n",
    "# resample from 22050 to 16000\n",
    "audio_each_file = librosa.resample(audio_each_file, orig_sr=sr, target_sr=16000)\n",
    "print(audio_each_file.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load textgrid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0 0.53\n",
      "my 0.53 0.93\n",
      "favorite 0.93 1.34\n",
      "kind 1.34 1.57\n",
      "of 1.57 1.65\n",
      "movies 1.65 2.2\n",
      "are 2.2 2.45\n",
      "romantic 2.45 3.2\n",
      "movies 3.2 3.72\n",
      " 3.72 3.75\n",
      "such 3.75 4.1\n",
      "as 4.1 4.33\n",
      "titanic 4.33 5.23\n",
      " 5.23 5.78\n",
      "it's 5.78 6.19\n",
      "a 6.19 6.46\n",
      " 6.46 6.49\n",
      "fantastic 6.49 7.13\n",
      "film 7.13 7.56\n",
      "it 7.56 7.77\n",
      "captured 7.77 8.28\n",
      "many 8.28 8.73\n",
      "young 8.73 9.1\n",
      "people's 9.1 9.44\n",
      "hearts 9.44 9.79\n",
      "with 9.79 10.02\n",
      "it's 10.02 10.17\n",
      "amazing 10.17 10.65\n",
      "music 10.65 11.12\n",
      "and 11.12 11.36\n",
      "sentimental 11.36 11.92\n",
      "plots 11.92 12.47\n",
      " 12.47 12.84\n",
      "when 12.84 12.98\n",
      "i 12.98 13.12\n",
      "think 13.12 13.28\n",
      "of 13.28 13.35\n",
      "the 13.35 13.42\n",
      "movie 13.42 13.62\n",
      "titanic 13.62 14.2\n",
      " 14.2 14.23\n",
      "the 14.23 14.42\n",
      "word 14.42 14.92\n",
      "that 14.92 15.06\n",
      "comes 15.06 15.3\n",
      "to 15.3 15.39\n",
      "my 15.39 15.5\n",
      "mind 15.5 15.91\n",
      "mind 15.91 16.06\n",
      " 16.06 16.41\n",
      "to 16.41 16.6\n",
      "mises 16.6 17.07\n",
      "the 17.07 17.15\n",
      "whole 17.15 17.39\n",
      "film 17.39 17.94\n",
      " 17.94 17.97\n",
      "would 17.97 18.18\n",
      "be 18.18 18.62\n",
      " 18.62 19.09\n",
      "love 19.09 19.94\n",
      " 19.94 20.07\n",
      "it's 20.07 20.27\n",
      "a 20.27 20.36\n",
      "kind 20.36 20.83\n",
      "of 20.83 20.98\n",
      "thing 20.98 21.25\n",
      "that 21.25 21.43\n",
      "makes 21.43 21.8\n",
      "you 21.8 22.28\n",
      " 22.28 22.31\n",
      "makes 22.31 22.8\n",
      "the 22.8 22.91\n",
      "world 22.91 23.21\n",
      "go 23.21 23.38\n",
      "round 23.38 23.87\n",
      " 23.87 24.08\n",
      "watching 24.08 24.6\n",
      "these 24.6 24.8\n",
      "kinds 24.8 25.18\n",
      "of 25.18 25.29\n",
      "romantic 25.29 25.83\n",
      "movies 25.83 26.23\n",
      "is 26.23 26.43\n",
      "just 26.43 26.86\n",
      "like 26.86 27.07\n",
      "reading 27.07 27.49\n",
      "a 27.49 27.56\n",
      "book 27.56 27.98\n",
      " 27.98 28.11\n",
      "that 28.11 28.29\n",
      "teaches 28.29 28.65\n",
      "me 28.65 28.78\n",
      "how 28.78 28.99\n",
      "to 28.99 29.19\n",
      "love 29.19 29.61\n",
      "and 29.61 29.93\n",
      "be 29.93 30.09\n",
      "loved 30.09 30.53\n",
      " 30.53 30.96\n",
      "moreover 30.96 31.68\n",
      "we 31.68 31.81\n",
      " 31.81 32.01\n",
      "can 32.01 32.51\n",
      " 32.51 32.56\n",
      "learn 32.56 32.72\n",
      "we 32.72 33.09\n",
      "can 33.09 33.25\n",
      "learn 33.25 34.05\n",
      " 34.05 34.2\n",
      "more 34.2 35.12\n",
      "from 35.12 35.44\n",
      "it 35.44 35.66\n",
      "such 35.66 35.98\n",
      "things 35.98 36.35\n",
      "as 36.35 36.69\n",
      " 36.69 36.89\n",
      "loyalty 36.89 37.59\n",
      "and 37.59 37.76\n",
      "what 37.76 37.88\n",
      "we 37.88 37.99\n",
      "treasure 37.99 38.47\n",
      "in 38.47 38.58\n",
      "our 38.58 38.71\n",
      "lives 38.71 39.11\n",
      " 39.11 39.4\n",
      "another 39.4 39.8\n",
      "movie 39.8 40.13\n",
      "about 40.13 40.51\n",
      "love 40.51 40.83\n",
      "is 40.83 41.08\n",
      "the 41.08 41.24\n",
      " 41.24 41.3\n",
      "secret 41.3 41.9\n",
      " 41.9 42.13\n",
      "the 42.13 42.47\n",
      "movie 42.47 43.01\n",
      "secret 43.01 43.58\n",
      "is 43.58 43.71\n",
      "about 43.71 44.1\n",
      "a 44.1 44.15\n",
      "story 44.15 44.88\n",
      " 44.88 44.95\n",
      "of 44.95 45.14\n",
      "a 45.14 45.21\n",
      "musical 45.21 45.56\n",
      "prodigy 45.56 45.96\n",
      "do 45.96 46.04\n",
      "that 46.04 46.17\n",
      "falls 46.17 46.42\n",
      "in 46.42 46.49\n",
      "love 46.49 46.62\n",
      "with 46.62 46.72\n",
      "a 46.72 46.85\n",
      " 46.85 46.91\n",
      "girl 46.91 47.21\n",
      "who's 47.21 47.46\n",
      "dying 47.46 48.01\n",
      " 48.01 49.08\n",
      "there 49.08 49.33\n",
      "are 49.33 49.39\n",
      "a 49.39 49.46\n",
      "lot 49.46 49.82\n",
      "of 49.82 50.2\n",
      " 50.2 50.29\n",
      "enviable 50.29 50.88\n",
      "moments 50.88 51.3\n",
      "in 51.3 51.37\n",
      "this 51.37 51.53\n",
      "film 51.53 51.77\n",
      "such 51.77 52.01\n",
      "as 52.01 52.2\n",
      "the 52.2 52.3\n",
      "simple 52.3 52.57\n",
      "love 52.57 52.74\n",
      "between 52.74 53.06\n",
      "high 53.06 53.26\n",
      "school 53.26 53.52\n",
      "students 53.52 54.09\n",
      " 54.09 54.32\n",
      "every 54.32 54.56\n",
      "time 54.56 54.93\n",
      " 54.93 54.96\n",
      "i 54.96 55.08\n",
      "watch 55.08 55.45\n",
      "this 55.45 55.68\n",
      "movie 55.68 55.89\n",
      "it 55.89 55.98\n",
      "reminds 55.98 56.44\n",
      "me 56.44 56.55\n",
      "of 56.55 56.63\n",
      "a 56.63 56.7\n",
      "time 56.7 56.99\n",
      "that 56.99 57.08\n",
      "i 57.08 57.13\n",
      "was 57.13 57.23\n",
      "in 57.23 57.29\n",
      "high 57.29 57.53\n",
      "school 57.53 57.88\n",
      "and 57.88 58.03\n",
      " 58.03 58.25\n",
      "you 58.25 58.4\n",
      "might 58.4 58.55\n",
      "remember 58.55 59.1\n",
      " 59.1 59.29\n",
      "the 59.29 59.44\n",
      "crush 59.44 59.83\n",
      "you 59.83 59.94\n",
      "had 59.94 60.16\n",
      "in 60.16 60.27\n",
      "school 60.27 60.74\n",
      " 60.74 60.9\n",
      "and 60.9 61.12\n",
      "how 61.12 61.24\n",
      "you 61.24 61.36\n",
      "would 61.36 61.48\n",
      "look 61.48 61.7\n",
      "at 61.7 61.77\n",
      "him 61.77 62.16\n",
      " 62.16 62.37\n",
      "while 62.37 62.54\n",
      "he's 62.54 62.74\n",
      "at 62.74 63.02\n",
      "in 63.02 63.61\n",
      "class 63.61 64.04\n",
      "without 64.04 64.38\n",
      "thinking 64.38 64.83\n",
      "or 64.83 64.95\n",
      " 64.95 64.98\n",
      "wanting 64.98 65.27\n",
      "to 65.27 65.36\n",
      "go 65.36 65.54\n",
      "places 65.54 65.95\n",
      "with 65.95 66.12\n",
      "him 66.12 66.38\n",
      " 66.38 67.0\n"
     ]
    }
   ],
   "source": [
    "import textgrid as tg\n",
    "\n",
    "vocab_path = \"./EMAGE/test_sequences/weights/vocab.pkl\"\n",
    "word_data_path = \"./EMAGE/test_sequences/textgrid/2_scott_0_4_4.TextGrid\"\n",
    "tgrid = tg.TextGrid.fromFile(word_data_path)\n",
    "for j, word in enumerate(tgrid[0]):\n",
    "    word_n, word_s, word_e = word.mark, word.minTime, word.maxTime\n",
    "    print(word_n, word_s, word_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### npy(T,h,w,3) to mp4 video via cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "img_sequence = np.load(\"out5.npy\")\n",
    "print(img_sequence.shape)\n",
    "img_sequence = (img_sequence).astype(np.uint8)\n",
    "\n",
    "height, width, _ = img_sequence.shape[1:4]\n",
    "size = (width, height)\n",
    "out = cv2.VideoWriter('pred_nobody.mp4', cv2.VideoWriter_fourcc(*'MP4V'), 30, size)\n",
    "\n",
    "for img in img_sequence:\n",
    "    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    out.write(img_bgr)\n",
    "\n",
    "\n",
    "out.release()\n",
    "\n",
    "print(\"fin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wav chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "scene01_audio_path = \"../../../dataset/PXB184/scene01_audio.wav\"\n",
    "audio_each_file, sr = librosa.load(scene01_audio_path)\n",
    "\n",
    "print(audio_each_file.shape, sr) \n",
    "\n",
    "fps = 30\n",
    "num_chunks = 15\n",
    "frame_per_chunk = 600\n",
    "chunk_duration = frame_per_chunk / fps # 20s\n",
    "samples_per_chunk = int(chunk_duration*sr) # 20*22050=\n",
    "\n",
    "audio_chunks = [audio_each_file[i*samples_per_chunk:(i+1)*samples_per_chunk] for i in range(num_chunks)]\n",
    "\n",
    "for i, chunk in enumerate(audio_chunks):\n",
    "    print(f\"chunk {i+1}: {chunk.shape}\")\n",
    "    start_sample = i*samples_per_chunk\n",
    "    end_sample = start_sample + samples_per_chunk\n",
    "    chunk = audio_each_file[start_sample:end_sample]\n",
    "\n",
    "    output_file_name = f\"scene01_audio_chunk_{i+1}.wav\"\n",
    "    output_path = f\"../../../dataset/PXB184/{output_file_name}\"\n",
    "\n",
    "    sf.write(output_path, chunk, sr)\n",
    "    print(f\"saved {output_file_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### video + audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_audio(vidname, audname, outname, fps=30):\n",
    "    import moviepy.editor as mpe\n",
    "    my_clip = mpe.VideoFileClip(vidname)\n",
    "\n",
    "    if my_clip.fps is None:\n",
    "        my_clip.fps = fps\n",
    "\n",
    "    audio_background = mpe.AudioFileClip(audname)\n",
    "    final_clip = my_clip.set_audio(audio_background)\n",
    "    final_fps = my_clip.fps if my_clip.fps is not None else fps\n",
    "\n",
    "    final_clip.write_videofile(outname,fps=final_fps)\n",
    "\n",
    "idx = 7\n",
    "vidname =f\"../../../../Videos/gt{idx}.mp4\"\n",
    "audname = f\"../../../dataset/PXB184/aa/scene01_audio_chunk_{idx}.wav\"\n",
    "combine_audio(vidname=vidname, audname=audname, outname=f\"combined{idx}.mp4\",fps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emage38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
